# -*- coding: utf-8 -*-
"""spotify data analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yOOX9zwlOo0rlBqTTvTOwThTPdaPV5A2
"""

!pip install pandas numpy matplotlib scikit-learn plotly scipy

import kagglehub

# Download latest version
path = kagglehub.dataset_download("ambaliyagati/spotify-dataset-for-playing-around-with-sql")

print("Path to dataset files:", path)

import os
from typing import List
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity

# ---------- CONFIG ----------
CSV_PATH = "/kaggle/input/spotify-dataset-for-playing-around-with-sql/spotify_tracks.csv"        # <-- change this to your CSV path
OUTPUT_DIR = "spotify_output"
RANDOM_SEED = 42
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Expected columns for convenience
EXPECTED_COLS = ["id", "name", "genre", "artists", "album", "popularity", "duration_ms", "explicit"]

# ---------- HELPERS ----------
def load_and_validate(path: str) -> pd.DataFrame:
    df = pd.read_csv(path, low_memory=False)
    df.columns = [c.strip() for c in df.columns]
    missing = [c for c in EXPECTED_COLS if c not in df.columns]
    if missing:
        raise ValueError(f"Missing expected columns in the CSV: {missing}")
    return df

def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    # Standardize text columns and handle nans
    text_cols = ["name", "genre", "artists", "album"]
    for c in text_cols:
        df[c] = df[c].astype(str).fillna("").str.strip()

    # Convert popularity to numeric (0-100)
    df["popularity"] = pd.to_numeric(df["popularity"], errors="coerce")
    # Convert duration
    df["duration_ms"] = pd.to_numeric(df["duration_ms"], errors="coerce")
    # convert explicit to boolean
    def parse_explicit(x):
        if pd.isna(x): return False
        if isinstance(x, bool): return bool(x)
        s = str(x).strip().lower()
        if s in ("1", "true", "t", "yes", "y"): return True
        if s in ("0", "false", "f", "no", "n"): return False
        return False
    df["explicit"] = df["explicit"].apply(parse_explicit)

    # Split artists into list
    df["artists_list"] = df["artists"].apply(lambda s: [a.strip() for a in s.split(",")] if s else [])
    # Make a unified "track_label" for display: "name — artists"
    df["track_label"] = df["name"].str.strip() + " — " + df["artists"].str.strip()
    # Safe index by id if available
    if df["id"].is_unique:
        df = df.set_index("id", drop=False)
    df = df.reset_index(drop=False)
    return df

def save_plot(fig, fname):
    path = os.path.join(OUTPUT_DIR, fname)
    fig.tight_layout()
    fig.savefig(path, dpi=150)
    plt.close(fig)
    print("Saved:", path)

# ---------- MAIN ----------
def main():
    print("Loading data from:", CSV_PATH)
    df = load_and_validate(CSV_PATH)
    print("Raw rows:", len(df))

    df = normalize_df(df)
    print("After normalize, rows:", len(df))

    # Quick Stats
    print("\n--- Quick stats ---")
    print("Total tracks:", len(df))
    if "popularity" in df.columns:
        print("Popularity: mean={:.1f}, median={:.1f}, std={:.1f}".format(
            df["popularity"].mean(skipna=True),
            df["popularity"].median(skipna=True),
            df["popularity"].std(skipna=True)
        ))
    if "duration_ms" in df.columns:
        print("Duration (s): mean={:.1f}, median={:.1f}".format(
            df["duration_ms"].mean(skipna=True)/1000.0,
            df["duration_ms"].median(skipna=True)/1000.0
        ))

    # Top genres
    top_genres = df["genre"].replace("", np.nan).value_counts().head(15)
    print("\nTop genres (by track count):")
    print(top_genres)

    # Explcit vs non-explicit
    expl_counts = df["explicit"].value_counts(dropna=False)
    print("\nExplicit counts:")
    print(expl_counts)

    # Top artists (explode artists_list)
    artists_expl = df.explode("artists_list")
    artist_counts = artists_expl["artists_list"].value_counts().head(20)
    print("\nTop artists (by track count in dataset):")
    print(artist_counts)

    # Save summaries
    top_genres.to_csv(os.path.join(OUTPUT_DIR, "top_genres.csv"))
    artist_counts.to_csv(os.path.join(OUTPUT_DIR, "top_artists.csv"))
    expl_counts.to_csv(os.path.join(OUTPUT_DIR, "explicit_counts.csv"))

    # ---------- VISUALIZATIONS ----------
    # 1) Popularity histogram
    fig = plt.figure(figsize=(8,4))
    ax = fig.subplots()
    df["popularity"].dropna().plot(kind="hist", bins=30, ax=ax)
    ax.set_title("Popularity distribution")
    ax.set_xlabel("Popularity (0-100)")
    save_plot(fig, "popularity_hist.png")

    # 2) Duration histogram (seconds)
    fig = plt.figure(figsize=(8,4))
    ax = fig.subplots()
    (df["duration_ms"] / 1000).dropna().plot(kind="hist", bins=40, ax=ax)
    ax.set_title("Track duration (seconds)")
    ax.set_xlabel("Duration (s)")
    save_plot(fig, "duration_hist.png")

    # 3) Top genres bar
    if len(top_genres) > 0:
        fig = plt.figure(figsize=(10,6))
        ax = fig.subplots()
        top_genres.plot(kind="barh", ax=ax)
        ax.invert_yaxis()
        ax.set_title("Top genres in dataset")
        save_plot(fig, "top_genres.png")

    # 4) Explicit vs non-explicit pie
    fig = plt.figure(figsize=(5,5))
    ax = fig.subplots()
    expl_counts.plot(kind="pie", autopct="%.1f%%", ax=ax)
    ax.set_ylabel("")
    ax.set_title("Explicit vs Non-explicit")
    save_plot(fig, "explicit_pie.png")

    # ---------- SIMPLE CONTENT-BASED RECOMMENDER ----------
    # We'll build a textual TF-IDF on: name + artists + album + genre
    df["text_for_tfidf"] = (
        df["name"].fillna("") + " | " +
        df["artists"].fillna("") + " | " +
        df["album"].fillna("") + " | " +
        df["genre"].fillna("")
    )

    # TF-IDF matrix
    tfv = TfidfVectorizer(min_df=1, max_df=0.9, ngram_range=(1,2))
    tfidf_matrix = tfv.fit_transform(df["text_for_tfidf"].values)

    # Numeric features we can add: popularity (scaled), duration_ms (scaled)
    numeric_feats = []
    if "popularity" in df.columns:
        numeric_feats.append("popularity")
    if "duration_ms" in df.columns:
        numeric_feats.append("duration_ms")

    numeric_matrix = None
    if numeric_feats:
        scaler = StandardScaler()
        numeric_matrix = scaler.fit_transform(df[numeric_feats].fillna(0).values)
        # normalize numeric to unit-length rows to combine with tfidf (optional)
        from sklearn.preprocessing import normalize
        numeric_matrix = normalize(numeric_matrix, norm='l2')

    # Combine textual and numeric into final feature matrix for similarity
    if numeric_matrix is not None:
        # convert numeric to sparse and hstack
        from scipy.sparse import hstack
        from scipy import sparse
        numeric_sparse = sparse.csr_matrix(numeric_matrix)
        feature_matrix = hstack([tfidf_matrix, numeric_sparse], format='csr')
    else:
        feature_matrix = tfidf_matrix

    # Precompute cosine similarity (sparse-friendly)
    # We'll provide a recommend function that uses cosine similarity
    def recommend_by_track(track_identifier: str, top_n: int = 10):
        """
        track_identifier: either exact 'track_label' (name — artists) OR id (if present)
        returns a DataFrame with recommended tracks and similarity scores
        """
        # Try to find by id first
        candidate_idx = None
        # if user passed an id present in df['id']
        if track_identifier in df["id"].astype(str).values:
            candidate_idx = int(df.index[df["id"].astype(str) == track_identifier][0])
        else:
            # try exact match on track_label
            matches = df.index[df["track_label"].str.lower() == track_identifier.lower()].tolist()
            if matches:
                candidate_idx = matches[0]
            else:
                # try partial match in track_label
                partials = df.index[df["track_label"].str.lower().str.contains(track_identifier.lower())].tolist()
                if partials:
                    candidate_idx = partials[0]

        if candidate_idx is None:
            raise ValueError("Track identifier not found (tried id, exact track_label, and partial match).")

        query_vec = feature_matrix[candidate_idx]
        # compute cosine similarity to every track (this returns 1.0 for itself)
        sims = cosine_similarity(feature_matrix, query_vec).ravel()
        # Get top_n + 1 (because the first will be the track itself)
        top_indices = sims.argsort()[::-1][1: top_n + 1]
        results = []
        for idx in top_indices:
            results.append({
                "id": df.at[idx, "id"],
                "track_label": df.at[idx, "track_label"],
                "similarity": float(sims[idx]),
                "popularity": df.at[idx, "popularity"] if "popularity" in df.columns else np.nan,
                "duration_s": (df.at[idx, "duration_ms"] / 1000.0) if "duration_ms" in df.columns else np.nan,
                "explicit": df.at[idx, "explicit"]
            })
        return pd.DataFrame(results)

    # Save feature matrix artifacts (small)
    # Note: don't save TF-IDF matrix (it may be large). Save the corpus and vectorizer vocabulary.
    vocab_path = os.path.join(OUTPUT_DIR, "tfidf_vocabulary.txt")
    with open(vocab_path, "w", encoding="utf-8") as fh:
        for term, idx in sorted(tfv.vocabulary_.items(), key=lambda kv: kv[1]):
            fh.write(f"{term}\n")
    print("Saved TF-IDF vocabulary to:", vocab_path)

    # Save cleaned CSV
    cleaned_path = os.path.join(OUTPUT_DIR, "spotify_cleaned.csv")
    df.to_csv(cleaned_path, index=False)
    print("Saved cleaned data to:", cleaned_path)

    # Print example recommendations for the first track
    try:
        sample_label = df["track_label"].iloc[0]
        print("\nExample recommendations for:", sample_label)
        recs = recommend_by_track(sample_label, top_n=8)
        print(recs.head(8).to_string(index=False))
        recs.to_csv(os.path.join(OUTPUT_DIR, "example_recommendations.csv"), index=False)
    except Exception as ex:
        print("Could not compute example recommendations:", ex)

    print("\nDone. Outputs are in folder:", OUTPUT_DIR)
    # Expose recommend function to the interactive user
    return recommend_by_track, df

# If script executed, run main
if __name__ == "__main__":
    recommend, df_out = main()
    # Example interactive usage (uncomment to test)
    # print(recommend("Some Song — Artist Name", top_n=5))

# spotify_visualization.py

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

# ---------- CONFIG ----------
CSV_PATH = "/kaggle/input/spotify-dataset-for-playing-around-with-sql/spotify_tracks.csv"  # ← Update your file path here
OUTPUT_DIR = "spotify_plots"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Load data
df = pd.read_csv(CSV_PATH)

# Convert data types
df["popularity"] = pd.to_numeric(df["popularity"], errors="coerce")
df["duration_ms"] = pd.to_numeric(df["duration_ms"], errors="coerce")
df["duration_min"] = df["duration_ms"] / 60000  # convert to minutes

# Standardize explicit column
df["explicit"] = df["explicit"].astype(str).str.lower().isin(["true","1","yes","t"])

# Set style
sns.set(style="whitegrid")

# 1️⃣ Popularity Distribution
plt.figure(figsize=(8,5))
sns.histplot(df["popularity"], bins=30, kde=True)
plt.title("Popularity Distribution")
plt.xlabel("Popularity (0-100)")
plt.ylabel("Track Count")
plt.savefig(f"{OUTPUT_DIR}/popularity_distribution.png", dpi=150)
plt.show()

# 2️⃣ Track Duration Distribution
plt.figure(figsize=(8,5))
sns.histplot(df["duration_min"], bins=40, kde=True)
plt.title("Track Duration Distribution")
plt.xlabel("Duration (minutes)")
plt.ylabel("Track Count")
plt.savefig(f"{OUTPUT_DIR}/duration_distribution.png", dpi=150)
plt.show()

# 3️⃣ Top Genres Visualization
top_genres = df["genre"].value_counts().head(15)
plt.figure(figsize=(10,6))
sns.barplot(x=top_genres.values, y=top_genres.index, palette="viridis")
plt.title("Top 15 Genres in Dataset")
plt.xlabel("Number of Tracks")
plt.ylabel("Genre")
plt.savefig(f"{OUTPUT_DIR}/top_genres.png", dpi=150)
plt.show()

# 4️⃣ Explicit vs Non-Explicit Songs
plt.figure(figsize=(6,6))
df["explicit"].value_counts().plot.pie(
    labels=["Non-Explicit", "Explicit"] if True in df["explicit"].unique() else df["explicit"].unique(),
    autopct="%.1f%%",
    colors=["#66b3ff", "#ff9999"],
)
plt.title("Explicit vs Non-Explicit Tracks")
plt.ylabel("")
plt.savefig(f"{OUTPUT_DIR}/explicit_pie.png", dpi=150)
plt.show()

print(f"\n✅ Plots saved in folder: {OUTPUT_DIR}")